{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read mji csv and grab needed columns \n",
    "df_mji = pd.read_csv('/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/MJI/MJI_data.csv', keep_default_na=False, dtype='string')\n",
    "df_mji_small = pd.DataFrame(columns=['Title', 'Description', 'URL'])\n",
    "df_mji_small['Title'] = df_mji['Title'].str.lower().str.strip()\n",
    "df_mji_small['Description'] = df_mji['Description'].str.lower().str.strip()\n",
    "df_mji_small['URL'] = df_mji['URL'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read musow json dump and grab needed columns\n",
    "with open('/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/MUSOW/musow_name_desc_url_cat.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "musow_names = [result['name']['value'].strip().lower() for result in data['results']['bindings']]\n",
    "musow_desc = [result['description']['value'].strip().lower() for result in data['results']['bindings']]\n",
    "musow_url = [result['url']['value'].strip().lower() for result in data['results']['bindings']]\n",
    "df_musow = pd.DataFrame(columns=['Title', 'Description', 'URL'])\n",
    "df_musow['Title'] = musow_names\n",
    "df_musow['Description'] = musow_desc\n",
    "df_musow['URL'] = musow_url\n",
    "df_musow = df_musow.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove musow duplicates from MJI set \n",
    "mji_training_set = df_mji_small[~df_mji_small['Title'].isin(df_musow['Title'])].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create positive and negative sets w/o additions\n",
    "positive_df = df_musow.copy()\n",
    "positive_df['Target'] = '1'\n",
    "negative_df = mji_training_set.copy()\n",
    "negative_df['Target'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create positive and negative sets w/ additions\n",
    "ismir_df = pd.read_pickle('/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/GH_PICKLES/ismir.pkl')\n",
    "ismir_df = ismir_df[~ismir_df['Title'].isin(df_musow['Title'])].dropna() \n",
    "positive_df_adds = pd.concat([df_musow, ismir_df]).reset_index(drop=True)\n",
    "positive_df_adds = positive_df_adds.drop_duplicates(['Title'], keep='last')\n",
    "positive_df_adds['Target'] = '1'\n",
    "mji_additions_1 = pd.read_csv('/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/MJI/MJI_additions_for_LR.csv')\n",
    "mji_additions_1['Title'] = mji_additions_1['Title'].str.lower().str.strip()\n",
    "mji_additions_1['Description'] = mji_additions_1['Description'].str.lower().str.strip()\n",
    "mji_additions_1['URL'] = mji_additions_1['URL'].str.lower().str.strip()\n",
    "mji_additions_1 = mji_additions_1[~mji_additions_1['Title'].isin(df_musow['Title'])].dropna()\n",
    "negative_df_adds = pd.concat([mji_training_set, mji_additions_1]).reset_index(drop=True)\n",
    "negative_df_adds = negative_df_adds.drop_duplicates(['Title'], keep='last')\n",
    "negative_df_adds['Target'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both sets into one\n",
    "training_set = pd.concat([positive_df, negative_df])\n",
    "training_set['Target'] = training_set['Target'].astype('int')\n",
    "training_set = training_set.reset_index(drop=True)\n",
    "training_set_adds = pd.concat([positive_df_adds, negative_df_adds])\n",
    "training_set_adds['Target'] = training_set_adds['Target'].astype('int')\n",
    "training_set_adds = training_set_adds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create combined columns for desc+headline and desc+headline_url\n",
    "def tokenize_url(url:str):\n",
    "    url=url.replace(\"https\",\"\")\n",
    "    url=url.replace(\"http\",\"\")\n",
    "    url=url.replace(\"www\",\"\")   \n",
    "    url=re.sub(\"(\\W|_)+\",\" \",url)\n",
    "    return url\n",
    "\n",
    "#create tokenized URL field\n",
    "training_set['tokenized_url']=training_set['URL'].apply(lambda x:tokenize_url(x))\n",
    "#description + headline\n",
    "training_set['text_desc_headline'] = training_set['Description'] + ' '+ training_set['Title']\n",
    "#description + tokenized url\n",
    "training_set['text_desc_headline_url'] = training_set['Description'] + ' '+ training_set['Title']+\" \" + training_set['tokenized_url']\n",
    "\n",
    "#create tokenized URL field\n",
    "training_set_adds['tokenized_url']=training_set_adds['URL'].apply(lambda x:tokenize_url(x))\n",
    "#description + headline\n",
    "training_set_adds['text_desc_headline'] = training_set_adds['Description'] + ' '+ training_set_adds['Title']\n",
    "#description + tokenized url\n",
    "training_set_adds['text_desc_headline_url'] = training_set_adds['Description'] + ' '+ training_set_adds['Title']+\" \" + training_set_adds['tokenized_url']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>19th century california sheet music</th>\n",
       "      <th>19th-century american sheet music</th>\n",
       "      <th>312 soul</th>\n",
       "      <th>a corpus study of rock music</th>\n",
       "      <th>a-r editions' online music anthology</th>\n",
       "      <th>aaron copland collection</th>\n",
       "      <th>abc - the annotated beethoven corpus</th>\n",
       "      <th>abc notation</th>\n",
       "      <th>acoustiid api</th>\n",
       "      <th>acrcloud</th>\n",
       "      <th>...</th>\n",
       "      <th>womxn who rock digital oral history archive</th>\n",
       "      <th>world digital library</th>\n",
       "      <th>world radio history</th>\n",
       "      <th>world radio history archive</th>\n",
       "      <th>world war i sheet music</th>\n",
       "      <th>wsm radio</th>\n",
       "      <th>wwu music score portal</th>\n",
       "      <th>yale classical archives corpus</th>\n",
       "      <th>yaleâ€™s oral history of american music</th>\n",
       "      <th>yiddish sheet music</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  19th century california sheet music 19th-century american sheet music  \\\n",
       "0                                 0.0                               0.0   \n",
       "1                                 0.0                               0.0   \n",
       "2                                 0.0                               0.0   \n",
       "3                                 0.0                               0.0   \n",
       "4                                 0.0                               0.0   \n",
       "\n",
       "  312 soul a corpus study of rock music a-r editions' online music anthology  \\\n",
       "0      0.0                          0.0                                  0.0   \n",
       "1      0.0                          0.0                                  0.0   \n",
       "2      0.0                          0.0                                  0.0   \n",
       "3      0.0                          0.0                                  0.0   \n",
       "4      0.0                          0.0                                  0.0   \n",
       "\n",
       "  aaron copland collection abc - the annotated beethoven corpus abc notation  \\\n",
       "0                      0.0                                  0.0          0.0   \n",
       "1                      0.0                                  0.0          0.0   \n",
       "2                      0.0                                  0.0          0.0   \n",
       "3                      0.0                                  0.0          0.0   \n",
       "4                      0.0                                  0.0          0.0   \n",
       "\n",
       "  acoustiid api acrcloud  ... womxn who rock digital oral history archive  \\\n",
       "0           0.0      0.0  ...                                         0.0   \n",
       "1           0.0      0.0  ...                                         0.0   \n",
       "2           0.0      0.0  ...                                         0.0   \n",
       "3           0.0      0.0  ...                                         0.0   \n",
       "4           0.0      0.0  ...                                         0.0   \n",
       "\n",
       "  world digital library world radio history world radio history archive  \\\n",
       "0                   0.0                 0.0                         0.0   \n",
       "1                   0.0                 0.0                         0.0   \n",
       "2                   0.0                 0.0                         0.0   \n",
       "3                   0.0                 0.0                         0.0   \n",
       "4                   0.0                 0.0                         0.0   \n",
       "\n",
       "  world war i sheet music wsm radio wwu music score portal  \\\n",
       "0                     0.0       0.0                    0.0   \n",
       "1                     0.0       0.0                    0.0   \n",
       "2                     0.0       0.0                    0.0   \n",
       "3                     0.0       0.0                    0.0   \n",
       "4                     0.0       0.0                    0.0   \n",
       "\n",
       "  yale classical archives corpus yaleâ€™s oral history of american music  \\\n",
       "0                            0.0                                   0.0   \n",
       "1                            0.0                                   0.0   \n",
       "2                            0.0                                   0.0   \n",
       "3                            0.0                                   0.0   \n",
       "4                            0.0                                   0.0   \n",
       "\n",
       "  yiddish sheet music  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 623 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode categorical variables w/OneHotEncoder\n",
    "\n",
    "oe_style = OneHotEncoder() \n",
    "feature_cols_onehot = ['Title', 'Description', 'URL']\n",
    "oe_results = oe_style.fit_transform(training_set[[\"Title\"]])\n",
    "pd.DataFrame(oe_results.toarray(), columns=oe_style.categories_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorial variables w/ OrdinalEncoder\n",
    "training_set_ordinal = training_set.copy()\n",
    "ord_enc = OrdinalEncoder()\n",
    "training_set_ordinal[\"Title_encoded\"] = ord_enc.fit_transform(training_set_ordinal[[\"Title\"]])\n",
    "training_set_ordinal[\"Desc_encoded\"] = ord_enc.fit_transform(training_set_ordinal[[\"Description\"]])\n",
    "training_set_ordinal[\"URL_encoded\"] = ord_enc.fit_transform(training_set_ordinal[[\"URL\"]])\n",
    "training_set_ordinal[\"text_desc_headline_encoded\"] = ord_enc.fit_transform(training_set_ordinal[[\"text_desc_headline\"]])\n",
    "training_set_ordinal[\"text_desc_headline_url_encoded\"] = ord_enc.fit_transform(training_set_ordinal[[\"text_desc_headline_url\"]])\n",
    "\n",
    "training_set_ordinal_adds = training_set_adds.copy()\n",
    "ord_enc = OrdinalEncoder()\n",
    "training_set_ordinal_adds[\"Title_encoded\"] = ord_enc.fit_transform(training_set_ordinal_adds[[\"Title\"]])\n",
    "training_set_ordinal_adds[\"Desc_encoded\"] = ord_enc.fit_transform(training_set_ordinal_adds[[\"Description\"]])\n",
    "training_set_ordinal_adds[\"URL_encoded\"] = ord_enc.fit_transform(training_set_ordinal_adds[[\"URL\"]])\n",
    "training_set_ordinal_adds[\"text_desc_headline_encoded\"] = ord_enc.fit_transform(training_set_ordinal_adds[[\"text_desc_headline\"]])\n",
    "training_set_ordinal_adds[\"text_desc_headline_url_encoded\"] = ord_enc.fit_transform(training_set_ordinal_adds[[\"text_desc_headline_url\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode cat variables with label encoding\n",
    "training_set_label = training_set.copy()\n",
    "training_set_label[\"Title\"] = training_set_label[\"Title\"].astype('category')\n",
    "training_set_label[\"Description\"] = training_set_label[\"Description\"].astype('category')\n",
    "training_set_label[\"URL\"] = training_set_label[\"URL\"].astype('category')\n",
    "training_set_label[\"text_desc_headline\"] = training_set_label[\"text_desc_headline\"].astype('category')\n",
    "training_set_label[\"text_desc_headline_url\"] = training_set_label[\"text_desc_headline_url\"].astype('category')\n",
    "training_set_label[\"Title_cat\"] = training_set_label[\"Title\"].cat.codes\n",
    "training_set_label[\"Desc_cat\"] = training_set_label[\"Description\"].cat.codes\n",
    "training_set_label[\"URL_cat\"] = training_set_label[\"URL\"].cat.codes\n",
    "training_set_label[\"text_desc_headline_cat\"] = training_set_label[\"text_desc_headline\"].cat.codes\n",
    "training_set_label[\"text_desc_headline_url_cat\"] = training_set_label[\"text_desc_headline_url\"].cat.codes\n",
    "\n",
    "training_set_label_adds = training_set_adds.copy()\n",
    "training_set_label_adds[\"Title\"] = training_set_label_adds[\"Title\"].astype('category')\n",
    "training_set_label_adds[\"Description\"] = training_set_label_adds[\"Description\"].astype('category')\n",
    "training_set_label_adds[\"URL\"] = training_set_label_adds[\"URL\"].astype('category')\n",
    "training_set_label_adds[\"text_desc_headline\"] = training_set_label_adds[\"text_desc_headline\"].astype('category')\n",
    "training_set_label_adds[\"text_desc_headline_url\"] = training_set_label_adds[\"text_desc_headline_url\"].astype('category')\n",
    "training_set_label_adds[\"Title_cat\"] = training_set_label_adds[\"Title\"].cat.codes\n",
    "training_set_label_adds[\"Desc_cat\"] = training_set_label_adds[\"Description\"].cat.codes\n",
    "training_set_label_adds[\"URL_cat\"] = training_set_label_adds[\"URL\"].cat.codes\n",
    "training_set_label_adds[\"text_desc_headline_cat\"] = training_set_label_adds[\"text_desc_headline\"].cat.codes\n",
    "training_set_label_adds[\"text_desc_headline_url_cat\"] = training_set_label_adds[\"text_desc_headline_url\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features and targets\n",
    "feature_cols_ord = ['Title_encoded', 'Desc_encoded', 'URL_encoded']\n",
    "x_ord = training_set_ordinal[feature_cols_ord] # Features\n",
    "y_ord = training_set_ordinal.Target # Target variable\n",
    "\n",
    "x_ord_adds = training_set_ordinal_adds[feature_cols_ord] # Features\n",
    "y_ord_adds = training_set_ordinal_adds.Target # Target variable\n",
    "\n",
    "feature_cols_ord_comb = ['Title_encoded', 'Desc_encoded', 'URL_encoded', 'text_desc_headline_encoded', 'text_desc_headline_url_encoded']\n",
    "x_ord_comb = training_set_ordinal[feature_cols_ord_comb] # Features\n",
    "y_ord_comb = training_set_ordinal.Target # Target variable \n",
    "\n",
    "x_ord_comb_adds = training_set_ordinal_adds[feature_cols_ord_comb] # Features\n",
    "y_ord_comb_adds = training_set_ordinal_adds.Target # Target variable \n",
    "\n",
    "feature_cols_label = ['Title_cat', 'Desc_cat', 'URL_cat']\n",
    "x_label = training_set_label[feature_cols_label] # Features\n",
    "y_label = training_set_label.Target # Target variable\n",
    "\n",
    "x_label_adds = training_set_label_adds[feature_cols_label] # Features\n",
    "y_label_adds = training_set_label_adds.Target # Target variable\n",
    "\n",
    "feature_cols_label_comb = ['Title_cat', 'Desc_cat', 'URL_cat', 'text_desc_headline_cat', 'text_desc_headline_url_cat']\n",
    "x_label_comb = training_set_label[feature_cols_label] # Features\n",
    "y_label_comb = training_set_label.Target # Target variable\n",
    "\n",
    "x_label_comb_adds = training_set_label_adds[feature_cols_label_comb] # Features\n",
    "y_label_comb_adds = training_set_label_adds.Target # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marilena's version\n",
    "def lr(x,y):  \n",
    "    \"\"\" logistic regression\"\"\"\n",
    "    model = LogisticRegression(solver='liblinear', C=10.0,random_state=44)\n",
    "    y_pred = cross_val_predict(model, x, y, cv=10)\n",
    "    acc = cross_val_score(model, x, y, cv=10, scoring='precision')\n",
    "    print('MEAN PRECISION', np.mean(acc))\n",
    "    report = classification_report(y, y_pred)\n",
    "    print('report:', report, sep='\\n')\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN PRECISION 0.7325974028590527\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.39      0.45       250\n",
      "           1       0.74      0.83      0.78       514\n",
      "\n",
      "    accuracy                           0.69       764\n",
      "   macro avg       0.63      0.61      0.61       764\n",
      "weighted avg       0.67      0.69      0.67       764\n",
      "\n",
      "MEAN PRECISION 0.7930343559137847\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.02      0.03       128\n",
      "           1       0.79      0.97      0.87       498\n",
      "\n",
      "    accuracy                           0.78       626\n",
      "   macro avg       0.46      0.49      0.45       626\n",
      "weighted avg       0.66      0.78      0.70       626\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0\n",
      " 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(lr(x_ord_comb_adds, y_ord_comb_adds), lr(x_ord, y_ord)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training test version\n",
    "\n",
    "def lr_training(x,y):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)\n",
    "    logreg = LogisticRegression()\n",
    "    # fit the model with data\n",
    "    logreg.fit(x_train,y_train)\n",
    "    y_pred=logreg.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.743455497382199\n",
      "Precision: 0.7941176470588235\n",
      "Recall: 0.8372093023255814\n",
      "Accuracy: 0.7834394904458599\n",
      "Precision: 0.7973856209150327\n",
      "Recall: 0.976\n",
      "[[ 34  28]\n",
      " [ 21 108]] [[  1  31]\n",
      " [  3 122]]\n"
     ]
    }
   ],
   "source": [
    "print(lr_training(x_ord_adds, y_ord_adds), lr_training(x_ord, y_ord)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
