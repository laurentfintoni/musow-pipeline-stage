{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../'\n",
    "import csv , dateutil.parser , time\n",
    "from datetime import date , timedelta \n",
    "import os\n",
    "# classifier\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#!pip3 install trafilatura\n",
    "import trafilatura\n",
    "from transformers import pipeline\n",
    "#cleaning \n",
    "import emoji\n",
    "import re\n",
    "#functions\n",
    "import sys\n",
    "sys.path.append('/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/PYTHON_FILES')\n",
    "from LogReg_Searches import LogRegSearches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions training set\n",
    "archive_desc_training_v1 = pd.read_pickle(path+'LOGREG_RELEVANCE/TRAINING_SETS/archive_desc_training_v1.pkl')\n",
    "archive_desc_training_v2 = pd.read_pickle(path+'LOGREG_RELEVANCE/TRAINING_SETS/archive_desc_training_v2.pkl')\n",
    "\n",
    "# twitter training set\n",
    "twitter_training_set_v1 = pd.read_pickle(path+'LOGREG_RELEVANCE/TRAINING_SETS/twitter_training_v1.pkl')\n",
    "\n",
    "#kw and sites to remove from url and title strings \n",
    "discard = ['youtu', '404', 'Not Found', 'bandcamp', 'ebay', 'It needs a human touch', 'Page not found', 'open.spotify.com', 'We\\'re sorry...', 'Not Acceptable!', 'Access denied', '412 Error', 'goo.gl', 'instagr.am', 'soundcloud', 'apple.co', 'amzn', 'masterstillmusic', 'Facebook', 'facebook', 'sheetmusiclibrary.website', 'Unsupported browser', 'Last.fm', 'last.fm', 'amazon.com', 'tidal.com', 'tmblr.co', 'blogspot', 'dailymusicroll', 'PortalTaxiMusic', 'apple.news', 'yahoo.com', 'sheetmusicplus.com', 'musicnotes.com', 'musescore.com', 'etsy', 'nts.live', 'twitch.tv', 'YouTube', 'radiosparx.com', 'freemusicarchive.org', 'blastradio', 'opensea', 'mixcloud', 'catalog.works', 'nft', 'NFT', 'allmusic.com', 'foundation.app', 'Robot or human?', 'heardle', 'insession.agency', 'jobvite', 'career', 'docs.google.com/forms/', 'discogs.com', 'zora.co', 'play.google.com', 't.me', 'mintable.app', 'instagram', 'linkedin', 'forms.gle', 'vimeo', 'radioiita', 'spotify']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_training(t_input, t_feature, target, cv_int, score_type, filename, path):\n",
    "    \"\"\" Create a text classifier based on Logistic regression and TF-IDF. Use cross validation \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t_input: \n",
    "        dataframe of the training set\n",
    "    t_feature: \n",
    "        df column, text of tweet or description of the resource\n",
    "    target: \n",
    "        df column, [0,1] values\n",
    "    cv_int: int\n",
    "        the number of cross validation folding\n",
    "    score_type: str\n",
    "        precision or recall\n",
    "    filename: str\n",
    "        model file name\n",
    "    path: str\n",
    "        parent folder\n",
    "    \"\"\"\n",
    "    # TODO eda to define max_features=1000\n",
    "      \n",
    "    tfidf_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=1000) \n",
    "    x_train = tfidf_transformer.fit_transform(t_input[t_feature])\n",
    "    y_train = t_input[target].values\n",
    "    model = LogisticRegressionCV(solver='liblinear', random_state=44, cv=cv_int, scoring=score_type)\n",
    "    \n",
    "    # export\n",
    "    model.fit(x_train, y_train)\n",
    "    export_model = f'LOGREG_RELEVANCE/MODELS/{filename}_model.pkl'\n",
    "    export_vectorizer = f'LOGREG_RELEVANCE/MODELS/{filename}_vectorizer.pkl'\n",
    "    pickle.dump(model, open(path+export_model, 'wb'))\n",
    "    pickle.dump(tfidf_transformer, open(path+export_vectorizer, 'wb'))\n",
    "    \n",
    "    # report\n",
    "    y_pred = cross_val_predict(model, x_train, y_train, cv=cv_int)\n",
    "    report = classification_report(y_train, y_pred)\n",
    "    print('report:', report, sep='\\n')\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def lr_predict(path, filename, p_input, p_feature):\n",
    "    \"\"\" Classify text using a pickled model based on Logistic regression and TF-IDF.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p_input: \n",
    "        dataframe of the prediction set\n",
    "    p_feature: \n",
    "        df column, text of tweet or description of the resource\n",
    "    filename: str\n",
    "        model file name\n",
    "    path: str\n",
    "        parent folder\n",
    "    \"\"\"\n",
    "    export_model = f'{path}LOGREG_RELEVANCE/MODELS/{filename}_model.pkl'\n",
    "    export_vectorizer = f'{path}LOGREG_RELEVANCE/MODELS/{filename}_vectorizer.pkl'\n",
    "    model = pickle.load(open(export_model, 'rb'))\n",
    "    tfidf_transformer = pickle.load(open(export_vectorizer, 'rb'))\n",
    "  \n",
    "    #result = loaded_model.score(X_test, Y_test)\n",
    "    #x_new_count = count_vect.transform(p_input[p_feature])\n",
    "    x_predict = tfidf_transformer.transform(p_input[p_feature])\n",
    "    y_predict = model.predict(x_predict)\n",
    "    scores = model.decision_function(x_predict)\n",
    "    probability = model.predict_proba(x_predict)\n",
    "    \n",
    "    #results = [r for r in y_predict]\n",
    "    result = p_input.copy()\n",
    "    result['Prediction'] = y_predict\n",
    "    result['Score'] = scores\n",
    "    result['Probability'] = probability[:,1]\n",
    "    result['Input Length'] = result[p_feature].str.len()\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results):\n",
    "        search_url = \"https://api.twitter.com/2/tweets/search/all\" #Change to the endpoint you want to collect data from\n",
    "        #change params based on the endpoint you are using\n",
    "        query_params = {'query': keyword,\n",
    "                        'start_time': start_date,\n",
    "                        'end_time': end_date,\n",
    "                        'max_results': max_results,\n",
    "                        'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                        'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source,entities',\n",
    "                        'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                        'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                        'next_token': {}}\n",
    "        return (search_url, query_params)\n",
    "    \n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "#remove emojis from tweet    \n",
    "def give_emoji_free_text(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "def append_to_csv(json_response, fileName):\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    \n",
    "    #setup usernames via includes\n",
    "    username = {user['id']: user['username'] for user in json_response['includes']['users']}\n",
    "    \n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "\n",
    "        # 1. Username\n",
    "        author_id = tweet['author_id']\n",
    "        user = username[author_id]\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "\n",
    "        # 3. Language\n",
    "        lang = tweet['lang']\n",
    "\n",
    "        # 4. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "\n",
    "        #5. URLs w/ a catch for tweets w/ two links TODO: how to catch more than two links? \n",
    "        if ('entities' in tweet) and ('urls' in tweet['entities']):\n",
    "            for url in tweet['entities']['urls']:\n",
    "                url = [url['expanded_url'] for url in tweet['entities']['urls'] if 'twitter.com' not in url['expanded_url']]\n",
    "                url = ', '.join(url)\n",
    "        else:\n",
    "            url = \"\"\n",
    "        \n",
    "        #6. Tweet text\n",
    "        text = give_emoji_free_text(tweet['text']) \n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [user, created_at, lang, like_count, quote_count, reply_count, retweet_count, text, url]\n",
    "\n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1    \n",
    "    \n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) \n",
    "\n",
    "def twitter_search(token, keyword, start, end, mresults, mcount, file_name):\n",
    "    \n",
    "    # TODO filter tweets in english only OR tweak TF-IDF stopwords (lang detection)\n",
    "    bearer_token = token\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)} \n",
    "    start_list = start\n",
    "    end_list =  end\n",
    "    max_results = mresults\n",
    "    total_tweets = 0\n",
    "\n",
    "    # Create file\n",
    "    csvFile = open(f'{path}TWITTER_SEARCHES/RAW_SEARCHES/{file_name}.csv', \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow(['user', 'created_at', 'lang', 'like_count', 'quote_count', 'reply_count','retweet_count','tweet', 'URL'])\n",
    "    csvFile.close()\n",
    "\n",
    "    for i in range(0,len(start_list)):\n",
    "        # Inputs\n",
    "        count = 0 # Counting tweets per time period\n",
    "        max_count = mcount # Max tweets per time period\n",
    "        flag = True\n",
    "        next_token = None\n",
    "        \n",
    "        while flag:\n",
    "            # Check if max_count reached\n",
    "            if count >= max_count:\n",
    "                break\n",
    "            print(\"-------------------\")\n",
    "            print(\"Token: \", next_token)\n",
    "            url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "            json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "            result_count = json_response['meta']['result_count']\n",
    "\n",
    "            if 'next_token' in json_response['meta']:\n",
    "                # Save the token to use for next call\n",
    "                next_token = json_response['meta']['next_token']\n",
    "                print(\"Next Token: \", next_token)\n",
    "                if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                    print(\"Start Date: \", start_list[i])\n",
    "                    append_to_csv(json_response, f'{path}TWITTER_SEARCHES/RAW_SEARCHES/{file_name}.csv')\n",
    "                    count += result_count\n",
    "                    total_tweets += result_count\n",
    "                    print(f\"Total # of Tweets added for '{keyword}':\", total_tweets)\n",
    "                    print(\"-------------------\")\n",
    "                    time.sleep(5)                \n",
    "            # If no next token exists\n",
    "            else:\n",
    "                if result_count is not None and result_count > 0:\n",
    "                    print(\"-------------------\")\n",
    "                    print(\"Start Date: \", start_list[i])\n",
    "                    append_to_csv(json_response, f'{path}TWITTER_SEARCHES/RAW_SEARCHES/{file_name}.csv')\n",
    "                    count += result_count\n",
    "                    total_tweets += result_count\n",
    "                    print(f\"Total # of Tweets added for '{keyword}':\", total_tweets)\n",
    "                    print(\"-------------------\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "                #Since this is the final request, turn flag to false to move to the next time period.\n",
    "                flag = False\n",
    "                next_token = None\n",
    "            time.sleep(5)\n",
    "    print(\"Total number of results:\", total_tweets)\n",
    "    \n",
    "    df = pd.read_csv(f'{path}TWITTER_SEARCHES/RAW_SEARCHES/{file_name}.csv', keep_default_na=False, dtype={\"user\": \"string\", \"lang\": \"string\", \"tweet\": \"string\", \"URL\": \"string\"})\n",
    "    \n",
    "    # clean the tweet from meentions, hashtags, emojis\n",
    "    df['tweet'].replace( { r\"@[A-Za-z0-9_]+\": '' }, inplace= True, regex = True)\n",
    "    df['tweet'].replace( { r\"#\": '' }, inplace= True, regex = True)\n",
    "    \n",
    "    # remove tweets that are not in english, have empty URLs, or have duplicate URLs\n",
    "    df = df[df['lang'].isin(['en'])]\n",
    "    df = df[df.URL != '']\n",
    "    df = df.drop_duplicates(['URL'], keep='last')\n",
    "\n",
    "    #add a column for the search keyword\n",
    "    df['Search KW'] = keyword\n",
    "\n",
    "    #pickle df for reuse\n",
    "    df.to_pickle(f'{path}TWITTER_SEARCHES/RAW_SEARCHES/{file_name}.pkl')\n",
    "\n",
    "\n",
    "def scrape_links(link_list):\n",
    "    links = pd.DataFrame(columns=['Title', 'Description', 'URL'])\n",
    "    summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
    "    \n",
    "    for link in link_list:\n",
    "        URL = link\n",
    "        page = None\n",
    "        ARTICLE = ''\n",
    "        try:\n",
    "            x = requests.head(URL, timeout=15)\n",
    "            content_type = x.headers[\"Content-Type\"] if \"Content-Type\" in x.headers else \"None\"\n",
    "            if (\"text/html\" in content_type.lower()):\n",
    "                page = requests.get(URL, timeout=15)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if page:\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            title = ' '.join([t.text for t in soup.find('head').find_all('title')]).strip() \\\n",
    "                if soup and soup.find('head') and soup.find('body') is not None \\\n",
    "                else URL\n",
    "            \n",
    "            try:\n",
    "                downloaded = trafilatura.fetch_url(URL)\n",
    "                ARTICLE = trafilatura.extract(downloaded, include_comments=False, include_tables=True, target_language='en', deduplicate=True)\n",
    "            except Exception:\n",
    "                results = soup.find_all(['h1', 'p'])\n",
    "                text = [result.text for result in results]\n",
    "                ARTICLE = ' '.join(text)\n",
    "            \n",
    "            if ARTICLE is not None and len(ARTICLE) > 200:\n",
    "                # text summarisation\n",
    "                max_chunk = 500\n",
    "                #removing special characters and replacing with end of sentence\n",
    "                ARTICLE = ARTICLE.replace('.', '.<eos>')\n",
    "                ARTICLE = ARTICLE.replace('?', '?<eos>')\n",
    "                ARTICLE = ARTICLE.replace('!', '!<eos>')\n",
    "                sentences = ARTICLE.split('<eos>')\n",
    "                current_chunk = 0 \n",
    "                chunks = []\n",
    "\n",
    "                # split text to process\n",
    "                for sentence in sentences:\n",
    "                    if len(chunks) == current_chunk + 1: \n",
    "                        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
    "                            chunks[current_chunk].extend(sentence.split(' '))\n",
    "                        else:\n",
    "                            current_chunk += 1\n",
    "                            chunks.append(sentence.split(' '))\n",
    "                    else:\n",
    "                        chunks.append(sentence.split(' '))\n",
    "\n",
    "                for chunk_id in range(len(chunks)):\n",
    "                    chunks[chunk_id] = ' '.join(chunks[chunk_id])\n",
    "                try:\n",
    "                    res = summarizer(chunks, max_length=59, min_length=30, do_sample=False)\n",
    "                    # summary\n",
    "                    text = ' '.join([summ['summary_text'] for summ in res])\n",
    "                except Exception:\n",
    "                    text = ARTICLE\n",
    "                    continue\n",
    "            else:\n",
    "                text = ARTICLE\n",
    "            print(URL)\n",
    "            new_row = {'Title': title, 'Description': text, 'URL': URL.strip()}\n",
    "            new_df = pd.DataFrame(data=new_row, index=[0])\n",
    "            links = pd.concat([links, new_df], ignore_index=True)\n",
    "    discard = ['None', '! D O C T Y P E h t m l >', '! d o c t y p e h t m l >', '! D O C T Y P E H T M L >']\n",
    "    links = links.fillna('None')\n",
    "    links = links[~links.Description.str.contains('|'.join(discard))]\n",
    "    return links\n",
    "\n",
    "def twitter_predictions(path, filename, p_input, p_feature, score, discard, filter):\n",
    "    \"\"\" Predict relevant tweets using a pickled model based on Logistic regression and TF-IDF.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p_input: \n",
    "        dataframe of the prediction set\n",
    "    p_feature: \n",
    "        df column, text of tweet or description of the resource\n",
    "    filename: str\n",
    "        model file name\n",
    "    path: str\n",
    "        parent folder\n",
    "    score: int\n",
    "        which prediction score to filter the results by 1/0\n",
    "    discard: variable\n",
    "        a list of terms to check against to remove tweets\n",
    "    filter: str \n",
    "        a string against which to further filter predictions \n",
    "    \"\"\"\n",
    "    preds = lr_predict(path, filename, p_input, p_feature)\n",
    "    preds = preds.drop_duplicates(['tweet'], keep='last')\n",
    "    preds = preds.loc[preds['Prediction'] == score]\n",
    "    preds = preds[~preds.URL.str.contains('|'.join(discard))]\n",
    "    preds = preds.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "    preds = preds[['tweet', 'Prediction', 'Score', 'Probability', 'Input Length', 'URL', 'Search KW']]\n",
    "    if filter != '':\n",
    "        preds = preds[preds['tweet'].str.contains(filter)]\n",
    "        preds = preds.reset_index(drop=True)\n",
    "    return preds\n",
    "\n",
    "def resource_predictions(path, filename, p_input, p_feature, score, discard, savefile):\n",
    "    \"\"\" Predict relevant URL descriptions using a pickled model based on Logistic regression and TF-IDF.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p_input: \n",
    "        dataframe of the prediction set\n",
    "    p_feature: \n",
    "        df column, text of tweet or description of the resource\n",
    "    filename: str\n",
    "        model file name\n",
    "    path: str\n",
    "        parent folder\n",
    "    score: int\n",
    "        which prediction score to filter the results by 1/0\n",
    "    discard: variable\n",
    "        a list of terms to check against to remove tweets\n",
    "    savefile: str\n",
    "        name for the final csv to be saved under \n",
    "    \"\"\"\n",
    "    preds = lr_predict(path, filename, p_input, p_feature)\n",
    "    preds = preds.drop_duplicates(['Description'], keep='last')\n",
    "    preds = preds.loc[preds['Prediction'] == score]\n",
    "    preds = preds[~preds.URL.str.contains('|'.join(discard))]\n",
    "    preds = preds[~preds.Title.str.contains('|'.join(discard))]\n",
    "    preds = preds.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "    preds.to_csv(f'{path}LOGREG_RELEVANCE/PREDICTIONS/{savefile}.csv')\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training twitter and descriptions classifiers\n",
    "\n",
    "This is a ONE TIME operation. The models are pickled and loaded later to predict new results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time training on twitter\n",
    "#twitter_training_model = lr_training(twitter_training_set_v1, 'tweet', 'Target', 10, 'precision', 'twitter', path)\n",
    "\n",
    "# one time training on resources\n",
    "#resource_training_model = lr_training(archive_desc_training_v2, 'Description', 'Target', 10, 'f1','resources_v2',path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Twitter\n",
    "\n",
    "Calls Twitter API with the list of keywords and returns the table `prediction_twitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'AAAAAAAAAAAAAAAAAAAAAJgsNAEAAAAAQcsgbUnOJJmqmU483%2F8x6n9V1i8%3Df0qaEo9cV1sWP4eyNQ6E9s8BiRjvFTSN9mSqithe8uIXSNP68x'\n",
    "#a selection of keywords based on MJI and musoW datasets\n",
    "keywords = ['oral history', 'music magazine', 'sound archive', 'music history', 'music culture', 'music research', 'sheet music', 'music library', 'digital library', 'music collection', 'digital collection', 'sound recording', 'midi file', 'audio file', 'music information', 'musical score', 'digital score', 'song dataset', 'digital edition', 'digital archive', 'digital library', 'music archive', 'music library', 'archive collection']\n",
    "#transfer keywords to input list w/ additional twitter parameters, e.g. no retweets\n",
    "input_keywords = [f'\\\"{k}\\\" -is:retweet' for k in keywords] \n",
    "#input time periods for search as a comma separated list\n",
    "start = ['2022-04-01T00:00:00.000Z']\n",
    "end = ['2022-04-30T00:00:00.000Z']\n",
    "#input max results / counts, and path \n",
    "mresults = 500 # max tweets per json response (100-500)\n",
    "mcount = 500 # max tweets per search period \n",
    "#run the search! \n",
    "for k in input_keywords:\n",
    "    filename = re.sub(r\"([^A-Za-z0-9]+)\", '', k) + f'_{start[0][0:10]}' + f'_{end[-1][6:10]}'\n",
    "    filename = re.sub(r\"isretweet\", '', filename)\n",
    "    prediction_twitter = twitter_search(token, k, start, end, mresults, mcount, filename)\n",
    "\n",
    "#today = date.today()\n",
    "#week_ago = today - timedelta(days=7)\n",
    "#start = [week_ago.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")]\n",
    "#end = [today.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing your files\n",
    "raw_searches = path+'TWITTER_SEARCHES/RAW_SEARCHES/'\n",
    "\n",
    "# Create empty df to save data\n",
    "result = pd.DataFrame()\n",
    "tweets_to_classify = pd.DataFrame()\n",
    "\n",
    "# Loop over files and read pickles\n",
    "for file in os.listdir(raw_searches):\n",
    "    if file.endswith('2022-01-01_3-31.pkl'):\n",
    "        result = pd.read_pickle(raw_searches+file)\n",
    "    tweets_to_classify = pd.concat([tweets_to_classify, result])\n",
    "    tweets_to_classify = tweets_to_classify.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>URL</th>\n",
       "      <th>Search KW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuomas_ee</td>\n",
       "      <td>2022-01-30 16:27:08+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Interested in high-quality musicology research...</td>\n",
       "      <td>https://www.durham.ac.uk/departments/academic/...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ancientlyric</td>\n",
       "      <td>2022-01-30 02:03:04+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Each instrument in a mix costs $40-60/hour for...</td>\n",
       "      <td>http://Patreon.com/BettinaJoyDeGuzman</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melissachemam</td>\n",
       "      <td>2022-01-29 18:58:32+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The British Library launched a major research ...</td>\n",
       "      <td>https://www.rollingstone.co.uk/music/british-l...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRHCIUSB</td>\n",
       "      <td>2022-01-29 12:50:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One person finds a tucked away college archive...</td>\n",
       "      <td>https://losscaptureproject.cargo.site/More-tha...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KeithJonesJr</td>\n",
       "      <td>2022-01-29 05:14:58+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Did not know Marsha Ambrosius wrote this. I’m ...</td>\n",
       "      <td>https://hellobeautiful.com/2741812/marsha-ambr...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>saareman</td>\n",
       "      <td>2022-03-10 13:45:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Download the score at the Estonian Music Infor...</td>\n",
       "      <td>https://www.emic.ee/?sisu=uudis_edasi&amp;mid=27&amp;l...</td>\n",
       "      <td>\"music information\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>tt_edugraph</td>\n",
       "      <td>2022-03-09 16:15:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kolkata-based educational institutions and ass...</td>\n",
       "      <td>https://www.telegraphindia.com/edugraph/campus...</td>\n",
       "      <td>\"music information\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>CroatianMusic</td>\n",
       "      <td>2022-03-09 10:04:08+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We are looking forward to another performance ...</td>\n",
       "      <td>https://mic.hr/en/performance-of-detonis-the-w...</td>\n",
       "      <td>\"music information\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>bemoreloyal</td>\n",
       "      <td>2022-03-08 14:09:13+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>InternationalWomensDay \n",
       "\n",
       "Nadine is a research ...</td>\n",
       "      <td>https://bit.ly/3MA6Bhe</td>\n",
       "      <td>\"music information\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>AcousticShoppe</td>\n",
       "      <td>2022-03-07 20:52:20+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How Long Does It Take To Learn To Play The Gui...</td>\n",
       "      <td>https://www.theacousticshoppe.com/acoustic-mus...</td>\n",
       "      <td>\"music information\" -is:retweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user                 created_at lang like_count quote_count  \\\n",
       "0          tuomas_ee  2022-01-30 16:27:08+00:00   en         25           3   \n",
       "1       ancientlyric  2022-01-30 02:03:04+00:00   en          2           0   \n",
       "2      melissachemam  2022-01-29 18:58:32+00:00   en          0           0   \n",
       "3           CRHCIUSB  2022-01-29 12:50:00+00:00   en          0           0   \n",
       "4       KeithJonesJr  2022-01-29 05:14:58+00:00   en          0           1   \n",
       "...              ...                        ...  ...        ...         ...   \n",
       "7347        saareman  2022-03-10 13:45:46+00:00   en          1           0   \n",
       "7348     tt_edugraph  2022-03-09 16:15:00+00:00   en          0           0   \n",
       "7349   CroatianMusic  2022-03-09 10:04:08+00:00   en          0           0   \n",
       "7350     bemoreloyal  2022-03-08 14:09:13+00:00   en          3           0   \n",
       "7351  AcousticShoppe  2022-03-07 20:52:20+00:00   en          1           0   \n",
       "\n",
       "     reply_count retweet_count  \\\n",
       "0              0             8   \n",
       "1              0             1   \n",
       "2              0             0   \n",
       "3              0             0   \n",
       "4              0             1   \n",
       "...          ...           ...   \n",
       "7347           0             0   \n",
       "7348           0             0   \n",
       "7349           0             0   \n",
       "7350           0             1   \n",
       "7351           0             0   \n",
       "\n",
       "                                                  tweet  \\\n",
       "0     Interested in high-quality musicology research...   \n",
       "1     Each instrument in a mix costs $40-60/hour for...   \n",
       "2     The British Library launched a major research ...   \n",
       "3     One person finds a tucked away college archive...   \n",
       "4     Did not know Marsha Ambrosius wrote this. I’m ...   \n",
       "...                                                 ...   \n",
       "7347  Download the score at the Estonian Music Infor...   \n",
       "7348  Kolkata-based educational institutions and ass...   \n",
       "7349  We are looking forward to another performance ...   \n",
       "7350  InternationalWomensDay \n",
       "\n",
       "Nadine is a research ...   \n",
       "7351  How Long Does It Take To Learn To Play The Gui...   \n",
       "\n",
       "                                                    URL  \\\n",
       "0     https://www.durham.ac.uk/departments/academic/...   \n",
       "1                 http://Patreon.com/BettinaJoyDeGuzman   \n",
       "2     https://www.rollingstone.co.uk/music/british-l...   \n",
       "3     https://losscaptureproject.cargo.site/More-tha...   \n",
       "4     https://hellobeautiful.com/2741812/marsha-ambr...   \n",
       "...                                                 ...   \n",
       "7347  https://www.emic.ee/?sisu=uudis_edasi&mid=27&l...   \n",
       "7348  https://www.telegraphindia.com/edugraph/campus...   \n",
       "7349  https://mic.hr/en/performance-of-detonis-the-w...   \n",
       "7350                             https://bit.ly/3MA6Bhe   \n",
       "7351  https://www.theacousticshoppe.com/acoustic-mus...   \n",
       "\n",
       "                            Search KW  \n",
       "0        \"music research\" -is:retweet  \n",
       "1        \"music research\" -is:retweet  \n",
       "2        \"music research\" -is:retweet  \n",
       "3        \"music research\" -is:retweet  \n",
       "4        \"music research\" -is:retweet  \n",
       "...                               ...  \n",
       "7347  \"music information\" -is:retweet  \n",
       "7348  \"music information\" -is:retweet  \n",
       "7349  \"music information\" -is:retweet  \n",
       "7350  \"music information\" -is:retweet  \n",
       "7351  \"music information\" -is:retweet  \n",
       "\n",
       "[7352 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_to_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>URL</th>\n",
       "      <th>Search KW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuomas_ee</td>\n",
       "      <td>2022-01-30 16:27:08+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Interested in high-quality musicology research...</td>\n",
       "      <td>https://www.durham.ac.uk/departments/academic/...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ancientlyric</td>\n",
       "      <td>2022-01-30 02:03:04+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Each instrument in a mix costs $40-60/hour for...</td>\n",
       "      <td>http://Patreon.com/BettinaJoyDeGuzman</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melissachemam</td>\n",
       "      <td>2022-01-29 18:58:32+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The British Library launched a major research ...</td>\n",
       "      <td>https://www.rollingstone.co.uk/music/british-l...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CRHCIUSB</td>\n",
       "      <td>2022-01-29 12:50:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One person finds a tucked away college archive...</td>\n",
       "      <td>https://losscaptureproject.cargo.site/More-tha...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KeithJonesJr</td>\n",
       "      <td>2022-01-29 05:14:58+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Did not know Marsha Ambrosius wrote this. I’m ...</td>\n",
       "      <td>https://hellobeautiful.com/2741812/marsha-ambr...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>EshitePeter</td>\n",
       "      <td>2022-03-22 23:22:37+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check out this review of Peedoet:writers, musi...</td>\n",
       "      <td>https://goo.gl/maps/pfWC6mt7byfk2pwbA</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>HomesAtMetacoda</td>\n",
       "      <td>2022-03-22 21:25:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>An insight into how our brains respond to musi...</td>\n",
       "      <td>https://www.forbes.com/sites/evaamsen/2022/01/...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tuosmusic</td>\n",
       "      <td>2022-03-22 11:11:22+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Today's research seminar! \n",
       "\n",
       "Exploring Women’s ...</td>\n",
       "      <td>https://www.sheffield.ac.uk/music/research/res...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>AusMusician</td>\n",
       "      <td>2022-03-21 21:45:49+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Regional Music Research Group is kicking off i...</td>\n",
       "      <td>https://australianmusician.com.au/youre-invite...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>MusicMaynooth</td>\n",
       "      <td>2022-03-21 09:46:41+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>'‘Global Winds’: Circulations, Circularity, an...</td>\n",
       "      <td>https://www.maynoothuniversity.ie/music/events...</td>\n",
       "      <td>\"music research\" -is:retweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user                 created_at lang  like_count  quote_count  \\\n",
       "0          tuomas_ee  2022-01-30 16:27:08+00:00   en          25            3   \n",
       "1       ancientlyric  2022-01-30 02:03:04+00:00   en           2            0   \n",
       "4      melissachemam  2022-01-29 18:58:32+00:00   en           0            0   \n",
       "7           CRHCIUSB  2022-01-29 12:50:00+00:00   en           0            0   \n",
       "8       KeithJonesJr  2022-01-29 05:14:58+00:00   en           0            1   \n",
       "..               ...                        ...  ...         ...          ...   \n",
       "205      EshitePeter  2022-03-22 23:22:37+00:00   en           3            0   \n",
       "208  HomesAtMetacoda  2022-03-22 21:25:00+00:00   en           0            0   \n",
       "211        tuosmusic  2022-03-22 11:11:22+00:00   en           1            1   \n",
       "214      AusMusician  2022-03-21 21:45:49+00:00   en           0            0   \n",
       "217    MusicMaynooth  2022-03-21 09:46:41+00:00   en           3            0   \n",
       "\n",
       "     reply_count  retweet_count  \\\n",
       "0              0              8   \n",
       "1              0              1   \n",
       "4              0              0   \n",
       "7              0              0   \n",
       "8              0              1   \n",
       "..           ...            ...   \n",
       "205            0              0   \n",
       "208            0              0   \n",
       "211            0              0   \n",
       "214            0              1   \n",
       "217            0              2   \n",
       "\n",
       "                                                 tweet  \\\n",
       "0    Interested in high-quality musicology research...   \n",
       "1    Each instrument in a mix costs $40-60/hour for...   \n",
       "4    The British Library launched a major research ...   \n",
       "7    One person finds a tucked away college archive...   \n",
       "8    Did not know Marsha Ambrosius wrote this. I’m ...   \n",
       "..                                                 ...   \n",
       "205  Check out this review of Peedoet:writers, musi...   \n",
       "208  An insight into how our brains respond to musi...   \n",
       "211  Today's research seminar! \n",
       "\n",
       "Exploring Women’s ...   \n",
       "214  Regional Music Research Group is kicking off i...   \n",
       "217  '‘Global Winds’: Circulations, Circularity, an...   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://www.durham.ac.uk/departments/academic/...   \n",
       "1                http://Patreon.com/BettinaJoyDeGuzman   \n",
       "4    https://www.rollingstone.co.uk/music/british-l...   \n",
       "7    https://losscaptureproject.cargo.site/More-tha...   \n",
       "8    https://hellobeautiful.com/2741812/marsha-ambr...   \n",
       "..                                                 ...   \n",
       "205              https://goo.gl/maps/pfWC6mt7byfk2pwbA   \n",
       "208  https://www.forbes.com/sites/evaamsen/2022/01/...   \n",
       "211  https://www.sheffield.ac.uk/music/research/res...   \n",
       "214  https://australianmusician.com.au/youre-invite...   \n",
       "217  https://www.maynoothuniversity.ie/music/events...   \n",
       "\n",
       "                        Search KW  \n",
       "0    \"music research\" -is:retweet  \n",
       "1    \"music research\" -is:retweet  \n",
       "4    \"music research\" -is:retweet  \n",
       "7    \"music research\" -is:retweet  \n",
       "8    \"music research\" -is:retweet  \n",
       "..                            ...  \n",
       "205  \"music research\" -is:retweet  \n",
       "208  \"music research\" -is:retweet  \n",
       "211  \"music research\" -is:retweet  \n",
       "214  \"music research\" -is:retweet  \n",
       "217  \"music research\" -is:retweet  \n",
       "\n",
       "[78 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the search you want to classify \n",
    "tweets_to_predict = pd.read_pickle(path+'TWITTER_SEARCHES/RAW_SEARCHES/musicresearch_2022-01-01_3-31.pkl')\n",
    "tweets_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify tweets\n",
    "predicted = twitter_predictions(path, 'twitter', tweets_to_predict, 'tweet', 1, discard, '')\n",
    "predicted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://archive.org/details/stgigaarchive\n",
      "https://tickets.nfsa.gov.au/Events/WHEN-THE-CAMERA-STOPPED-ROLLING-Q-A\n",
      "https://fb.watch/cmoHcGeDdv/\n",
      "https://spoti.fi/3MDqpzA\n",
      "https://www.base.at/dorninger/soundmixer-2\n",
      "http://store.rocksound.tv/simpleplan-tw\n",
      "http://www.noise11.com/news/national-film-and-sound-archive-of-australia-restore-the-original-helen-reddy-i-am-woman-video-20220322\n",
      "https://freesound.org/\n",
      "https://tickets.nfsa.gov.au/Events/BLACK-ANZAC\n",
      "https://video.alexanderstreet.com/watch/operation-babylift\n",
      "https://fb.watch/cqYnrBpMUY/\n",
      "https://rsa.fau.edu/album/42327\n",
      "https://tinyurl.com/3ys8hsc6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 59, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pastdaily.com/2019/05/15/sir-simon-rattle-with-the-berlin-philharmonic-in-music-of-schoenberg-and-mahler-2010-past-daily-mid-week-concert/\n",
      "http://bit.ly/3IPdLLi\n",
      "https://pastdaily.com/2021/01/13/january-13-1982-big-freeze-of-82-on-going-situation-in-poland-a-sit-down-with-hosni-mubarak/\n",
      "https://bit.ly/3ODwhdT\n",
      "https://www.nfsa.gov.au/collection/curated/chris-bailey-interviewed-iain-shedden\n",
      "https://www.bl.uk/events/late-at-the-library-the-will-gregory-moog-ensemble\n",
      "http://www.divfuse.com\n",
      "https://www.bbc.co.uk/sounds/play/m0016h9r\n",
      "https://richmix.org.uk/events/mwalimu-express/\n",
      "https://www.eventbrite.co.uk/e/ya-lalla-jewish-saharans-singing-to-birth-tickets-277570158817\n",
      "https://www.realgonerocks.com/2020/10/the-fall-fall-sound-archive-vol-5-imperial-wax-solvent/\n",
      "https://www.afr.com/rear-window/national-screen-and-sound-archive-hunts-for-scott-love-rub-morrisson-20150813-giynw7\n"
     ]
    }
   ],
   "source": [
    "#get links from positive tweets results\n",
    "twitter_link_list = [link for link in predicted['URL']]\n",
    "\n",
    "#scrape URL list\n",
    "scraped_links = scrape_links(twitter_link_list)\n",
    "\n",
    "#merge w/ predictions and save for reuse\n",
    "twitter_scrapes_preds = pd.merge(predicted, scraped_links, on='URL')\n",
    "twitter_scrapes_preds.to_pickle(path+'LOGREG_RELEVANCE/SCRAPES/soundarchive_2022-04-01_4-30_scrapes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_scrapes_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Input Length</th>\n",
       "      <th>URL</th>\n",
       "      <th>Search KW</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Screen and Sound Archive is available in o...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.880747</td>\n",
       "      <td>0.979782</td>\n",
       "      <td>255</td>\n",
       "      <td>https://tinyurl.com/3ys8hsc6</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>West Glamorgan Screen and Sound Archive - Swansea</td>\n",
       "      <td>West Glamorgan Screen and Sound Archive is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFSA - National Film and Sound Archive of Aust...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.624148</td>\n",
       "      <td>0.932400</td>\n",
       "      <td>174</td>\n",
       "      <td>https://fb.watch/cmoHcGeDdv/</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>NFSA - National Film and Sound Archive of Aust...</td>\n",
       "      <td>Collection of General Motors Holden cinema an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feel free to jam with my new Sound Mixer 2 wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.310839</td>\n",
       "      <td>0.909771</td>\n",
       "      <td>196</td>\n",
       "      <td>https://www.base.at/dorninger/soundmixer-2</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>Sound Mixer #2 | Dorninger</td>\n",
       "      <td>Wolfgang Dorninger mixes field-recordings, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Sun 3 Apr, our family-friendly afternoon ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.946392</td>\n",
       "      <td>0.875053</td>\n",
       "      <td>146</td>\n",
       "      <td>https://richmix.org.uk/events/mwalimu-express/</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>Mwalimu Express - Rich Mix</td>\n",
       "      <td>Live African Music from the cream of London’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Supposedly this was a Vick's Vaporub ad starri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.733931</td>\n",
       "      <td>0.849915</td>\n",
       "      <td>260</td>\n",
       "      <td>https://www.afr.com/rear-window/national-scree...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>National Film and Sound Archive hunts for Scot...</td>\n",
       "      <td>National Film and Sound Archive hunts for Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>National Film and Sound Archive of Australia R...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.295110</td>\n",
       "      <td>0.785011</td>\n",
       "      <td>282</td>\n",
       "      <td>http://www.noise11.com/news/national-film-and-...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>http://www.noise11.com/news/national-film-and-...</td>\n",
       "      <td>The Australian Film and Sound Archive in Canb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Still rock in these smooth sounds, perfect wor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.112723</td>\n",
       "      <td>0.752636</td>\n",
       "      <td>129</td>\n",
       "      <td>https://archive.org/details/stgigaarchive</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>St. GIGA - Tide of Sound Archive : St. GIGA : ...</td>\n",
       "      <td>Reviewer: \"Thank you so much for archiving th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not sure, but you can learn a little more her...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467541</td>\n",
       "      <td>0.614802</td>\n",
       "      <td>182</td>\n",
       "      <td>https://bit.ly/3ODwhdT</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>Vivien Mepham on Mad Max | NFSA</td>\n",
       "      <td>Vivien Mepham worked on the original Mad Max ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>January 13, 1982 - The Big Freeze Of '82 - The...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463558</td>\n",
       "      <td>0.613858</td>\n",
       "      <td>269</td>\n",
       "      <td>https://pastdaily.com/2021/01/13/january-13-19...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>January 13, 1982 - The Big Freeze Of '82 - The...</td>\n",
       "      <td>The Big Freeze of 1982 dumped record amounts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Imperial Wax Solvent, one of *the* great late-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457169</td>\n",
       "      <td>0.612342</td>\n",
       "      <td>1400</td>\n",
       "      <td>https://www.realgonerocks.com/2020/10/the-fall...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>THE FALL – Fall Sound Archive Vol 5: Imperial ...</td>\n",
       "      <td>'Imperial Wax Solvent' is an album that has m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Also this week with CamFest: \n",
       "\n",
       "Affiliate Dr Va...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334804</td>\n",
       "      <td>0.582928</td>\n",
       "      <td>297</td>\n",
       "      <td>https://www.eventbrite.co.uk/e/ya-lalla-jewish...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>YA LALLA: JEWISH SAHARANS SINGING TO BIRTH Tic...</td>\n",
       "      <td>Dr Vanessa Paloma Elbaz presents new stories ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sir Bob Geldof famously said that rock music i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318654</td>\n",
       "      <td>0.578996</td>\n",
       "      <td>154</td>\n",
       "      <td>https://www.nfsa.gov.au/collection/curated/chr...</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>Chris Bailey, interviewed by Iain Shedden | NFSA</td>\n",
       "      <td>Chris Bailey discusses the early days of The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DIVFUSE Sound Archive Open Call No. 2 - 1 of 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135818</td>\n",
       "      <td>0.533902</td>\n",
       "      <td>272</td>\n",
       "      <td>http://www.divfuse.com</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>Project DIVFUSE</td>\n",
       "      <td>Project DIVFUSE is a new platform that first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>has a wonderful sound archive. Here's the lin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134273</td>\n",
       "      <td>0.533518</td>\n",
       "      <td>172</td>\n",
       "      <td>https://rsa.fau.edu/album/42327</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>| RSA</td>\n",
       "      <td>If a song listed below has not been digitized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I Just bought tickets to BLACK ANZAC https://t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037006</td>\n",
       "      <td>0.509250</td>\n",
       "      <td>271</td>\n",
       "      <td>https://tickets.nfsa.gov.au/Events/BLACK-ANZAC</td>\n",
       "      <td>\"sound archive\" -is:retweet</td>\n",
       "      <td>BLACK ANZAC | National Film and Sound Archive</td>\n",
       "      <td>Black Anzac is a feature-length documentary a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  Prediction     Score  \\\n",
       "0   Our Screen and Sound Archive is available in o...           1  3.880747   \n",
       "1   NFSA - National Film and Sound Archive of Aust...           1  2.624148   \n",
       "2   Feel free to jam with my new Sound Mixer 2 wit...           1  2.310839   \n",
       "3   This Sun 3 Apr, our family-friendly afternoon ...           1  1.946392   \n",
       "4   Supposedly this was a Vick's Vaporub ad starri...           1  1.733931   \n",
       "5   National Film and Sound Archive of Australia R...           1  1.295110   \n",
       "6   Still rock in these smooth sounds, perfect wor...           1  1.112723   \n",
       "7    Not sure, but you can learn a little more her...           1  0.467541   \n",
       "8   January 13, 1982 - The Big Freeze Of '82 - The...           1  0.463558   \n",
       "9   Imperial Wax Solvent, one of *the* great late-...           1  0.457169   \n",
       "10  Also this week with CamFest: \n",
       "\n",
       "Affiliate Dr Va...           1  0.334804   \n",
       "11  Sir Bob Geldof famously said that rock music i...           1  0.318654   \n",
       "12  DIVFUSE Sound Archive Open Call No. 2 - 1 of 5...           1  0.135818   \n",
       "13   has a wonderful sound archive. Here's the lin...           1  0.134273   \n",
       "14  I Just bought tickets to BLACK ANZAC https://t...           1  0.037006   \n",
       "\n",
       "    Probability  Input Length  \\\n",
       "0      0.979782           255   \n",
       "1      0.932400           174   \n",
       "2      0.909771           196   \n",
       "3      0.875053           146   \n",
       "4      0.849915           260   \n",
       "5      0.785011           282   \n",
       "6      0.752636           129   \n",
       "7      0.614802           182   \n",
       "8      0.613858           269   \n",
       "9      0.612342          1400   \n",
       "10     0.582928           297   \n",
       "11     0.578996           154   \n",
       "12     0.533902           272   \n",
       "13     0.533518           172   \n",
       "14     0.509250           271   \n",
       "\n",
       "                                                  URL  \\\n",
       "0                        https://tinyurl.com/3ys8hsc6   \n",
       "1                        https://fb.watch/cmoHcGeDdv/   \n",
       "2          https://www.base.at/dorninger/soundmixer-2   \n",
       "3      https://richmix.org.uk/events/mwalimu-express/   \n",
       "4   https://www.afr.com/rear-window/national-scree...   \n",
       "5   http://www.noise11.com/news/national-film-and-...   \n",
       "6           https://archive.org/details/stgigaarchive   \n",
       "7                              https://bit.ly/3ODwhdT   \n",
       "8   https://pastdaily.com/2021/01/13/january-13-19...   \n",
       "9   https://www.realgonerocks.com/2020/10/the-fall...   \n",
       "10  https://www.eventbrite.co.uk/e/ya-lalla-jewish...   \n",
       "11  https://www.nfsa.gov.au/collection/curated/chr...   \n",
       "12                             http://www.divfuse.com   \n",
       "13                    https://rsa.fau.edu/album/42327   \n",
       "14     https://tickets.nfsa.gov.au/Events/BLACK-ANZAC   \n",
       "\n",
       "                      Search KW  \\\n",
       "0   \"sound archive\" -is:retweet   \n",
       "1   \"sound archive\" -is:retweet   \n",
       "2   \"sound archive\" -is:retweet   \n",
       "3   \"sound archive\" -is:retweet   \n",
       "4   \"sound archive\" -is:retweet   \n",
       "5   \"sound archive\" -is:retweet   \n",
       "6   \"sound archive\" -is:retweet   \n",
       "7   \"sound archive\" -is:retweet   \n",
       "8   \"sound archive\" -is:retweet   \n",
       "9   \"sound archive\" -is:retweet   \n",
       "10  \"sound archive\" -is:retweet   \n",
       "11  \"sound archive\" -is:retweet   \n",
       "12  \"sound archive\" -is:retweet   \n",
       "13  \"sound archive\" -is:retweet   \n",
       "14  \"sound archive\" -is:retweet   \n",
       "\n",
       "                                                Title  \\\n",
       "0   West Glamorgan Screen and Sound Archive - Swansea   \n",
       "1   NFSA - National Film and Sound Archive of Aust...   \n",
       "2                          Sound Mixer #2 | Dorninger   \n",
       "3                          Mwalimu Express - Rich Mix   \n",
       "4   National Film and Sound Archive hunts for Scot...   \n",
       "5   http://www.noise11.com/news/national-film-and-...   \n",
       "6   St. GIGA - Tide of Sound Archive : St. GIGA : ...   \n",
       "7                     Vivien Mepham on Mad Max | NFSA   \n",
       "8   January 13, 1982 - The Big Freeze Of '82 - The...   \n",
       "9   THE FALL – Fall Sound Archive Vol 5: Imperial ...   \n",
       "10  YA LALLA: JEWISH SAHARANS SINGING TO BIRTH Tic...   \n",
       "11   Chris Bailey, interviewed by Iain Shedden | NFSA   \n",
       "12                                    Project DIVFUSE   \n",
       "13                                              | RSA   \n",
       "14      BLACK ANZAC | National Film and Sound Archive   \n",
       "\n",
       "                                          Description  \n",
       "0    West Glamorgan Screen and Sound Archive is a ...  \n",
       "1    Collection of General Motors Holden cinema an...  \n",
       "2    Wolfgang Dorninger mixes field-recordings, be...  \n",
       "3    Live African Music from the cream of London’s...  \n",
       "4    National Film and Sound Archive hunts for Sco...  \n",
       "5    The Australian Film and Sound Archive in Canb...  \n",
       "6    Reviewer: \"Thank you so much for archiving th...  \n",
       "7    Vivien Mepham worked on the original Mad Max ...  \n",
       "8    The Big Freeze of 1982 dumped record amounts ...  \n",
       "9    'Imperial Wax Solvent' is an album that has m...  \n",
       "10   Dr Vanessa Paloma Elbaz presents new stories ...  \n",
       "11   Chris Bailey discusses the early days of The ...  \n",
       "12   Project DIVFUSE is a new platform that first ...  \n",
       "13   If a song listed below has not been digitized...  \n",
       "14   Black Anzac is a feature-length documentary a...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resources_predictions = resource_predictions(path, 'resources_v2', twitter_scrapes_preds, 'Description', 1, discard, 'soundarchive_2022-04-01_4-30')\n",
    "resources_predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
