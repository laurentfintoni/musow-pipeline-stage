{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1 of small-scale discovery pipeline for twitter:\n",
    "- Predict if results of twitter searches are relevant (twitter specific training set)\n",
    "- Scrape relevant result URLs \n",
    "- Predict if URLs are relevant (musoW specific training set)\n",
    "- Return results in a table w/ all necessary info + prediction info (score etc)\n",
    "- Options to do additional filtering at result stages: filter for specific keywords, filter for language, filter for unwanted URLs\n",
    "\n",
    "TO DO:\n",
    "- Export twitter training to pkl to load faster\n",
    "- Add sites to blacklist before scraping\n",
    "- Add values to remove after scraping e.g 404 \n",
    "- Integrate twitter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "- Load libraries and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports + path\n",
    "from __future__ import print_function\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "pd.set_option('display.max_rows', 100)\n",
    "path = '/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Reg crossval function to check training tests \n",
    "def lr(x, y, cv_value, scoring_value, title):  \n",
    "    \"\"\" logistic regression\"\"\"\n",
    "    model = LogisticRegressionCV(solver='liblinear', random_state=44, cv=cv_value, scoring=scoring_value)\n",
    "    #model = LogisticRegression(solver='liblinear', C=10.0,random_state=44)\n",
    "    y_pred = cross_val_predict(model, x, y, cv=cv_value)\n",
    "    acc = cross_val_score(model, x, y, cv=cv_value, scoring=scoring_value)    \n",
    "    report = classification_report(y, y_pred)\n",
    "    return print(f'{title}\\n''MEAN PRECISION', np.mean(acc), 'report:', report, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION FUNCTION W/ and W/O LOGREGCV \n",
    "\n",
    "def lr_model_predict_cv(t_input, t_feature, target, cv_int, score_type, p_input, p_feature, filename, path):\n",
    "    count_vect = CountVectorizer()\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_count = count_vect.fit_transform(t_input[t_feature])\n",
    "    x_train = tfidf_transformer.fit_transform(x_count)\n",
    "    y_train = t_input[target].values\n",
    "    model = LogisticRegressionCV(solver='liblinear', random_state=44, cv=cv_int, scoring=score_type)\n",
    "    model.fit(x_train, y_train)\n",
    "    export = f'LOGREG_RELEVANCE/{filename}.sav'\n",
    "    pickle.dump(model, open(path+export, 'wb'))\n",
    "    x_new_count = count_vect.transform(p_input[p_feature])\n",
    "    x_new_train = tfidf_transformer.transform(x_new_count)\n",
    "    y_predict = model.predict(x_new_train)\n",
    "    scores = model.decision_function(x_new_train)\n",
    "    probability = model.predict_log_proba(x_new_train)\n",
    "    results = [r for r in y_predict]\n",
    "    result = p_input.copy()\n",
    "    result['Prediction'] = results\n",
    "    result['Score'] = [s for s in scores]\n",
    "    result['Probability'] = [p for p in probability]\n",
    "    result['Input Length'] = result[p_feature].str.len()\n",
    "    return result\n",
    "\n",
    "def lr_model_predict(t_input, t_feature, target, p_input, p_feature, filename, path):\n",
    "    count_vect = CountVectorizer()\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_count = count_vect.fit_transform(t_input[t_feature])\n",
    "    x_train = tfidf_transformer.fit_transform(x_count)\n",
    "    y_train = t_input[target].values\n",
    "    model = LogisticRegression(solver='liblinear', C=10.0,random_state=44)\n",
    "    model.fit(x_train, y_train)\n",
    "    export = f'LOGREG_RELEVANCE/{filename}.sav'\n",
    "    pickle.dump(model, open(path+export, 'wb'))\n",
    "    x_new_count = count_vect.transform(p_input[p_feature])\n",
    "    x_new_train = tfidf_transformer.transform(x_new_count)\n",
    "    y_predict = model.predict(x_new_train)\n",
    "    scores = model.decision_function(x_new_train)\n",
    "    probability = model.predict_log_proba(x_new_train)\n",
    "    results = [r for r in y_predict]\n",
    "    result = p_input.copy()\n",
    "    result['Prediction'] = results\n",
    "    result['Score'] = [s for s in scores]\n",
    "    result['Probability'] = [p for p in probability]\n",
    "    result['Input Length'] = result[p_feature].str.len()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape URLs for title, desc and URL text \n",
    "\n",
    "def scrape_links(link_list):\n",
    "    links = pd.DataFrame(columns=['Title', 'Description', 'URL'])\n",
    "    for link in link_list:\n",
    "        URL = link\n",
    "        try:\n",
    "            page = requests.get(URL)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            pass\n",
    "        except Exception:\n",
    "            continue\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        if soup and soup.find('head') and soup.find('body') is not None:\n",
    "            title = ' '.join([t.text for t in soup.find('head').find_all('title')]).strip()\n",
    "            text = ' '.join([p.text for p in soup.find('body').find_all('p')]).strip()\n",
    "            new_row = {'Title': title, 'Description': text, 'URL': URL.strip()}\n",
    "            links = links.append(new_row, ignore_index=True)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "- load training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description training set \n",
    "training_set_even_adds = pd.read_pickle(path+'LOGREG_RELEVANCE/trainingset_even_extended.pkl')\n",
    "new_training_set = pd.read_pickle(path+'new_training_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative twitter training set\n",
    "#music_culture = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_music_culture.pkl')\n",
    "#music_history = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_music_history.pkl')\n",
    "#music_magazine = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_music_magazine.pkl')\n",
    "#music_oral_h = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_music_oral_history.pkl')\n",
    "#music_research = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_music_research.pkl')\n",
    "#sound_archive = pd.read_pickle(path+'TWITTER_SEARCHES/MJI BIGRAMS (NEGATIVE)/twitter_sound_archive.pkl')\n",
    "dh = pd.read_pickle(path+'TWITTER_SEARCHES/NEGATIVE/digital_humanities_2021.pkl')\n",
    "music_company = pd.read_pickle(path+'TWITTER_SEARCHES/NEGATIVE/music_company_2021.pkl')\n",
    "twitter_neg = pd.concat([dh, music_company])\n",
    "twitter_neg['Target'] = '0'\n",
    "twitter_neg = twitter_neg[['tweet', 'Target']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive twitter training set \n",
    "midi_file = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_midi_file.pkl')\n",
    "music_collection = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_music_collection.pkl')\n",
    "music_dataset = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_music_dataset.pkl')\n",
    "music_data = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_music_data.pkl')\n",
    "music_library = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_music_library.pkl')\n",
    "sheet_music = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_sheet_music.pkl')\n",
    "song_dataset = pd.read_pickle(path+'TWITTER_SEARCHES/MUSOW BIGRAMS (POSITIVE)/twitter_song_dataset.pkl')\n",
    "twitter_pos = pd.concat([midi_file, music_collection, music_dataset, music_data, music_library, sheet_music, song_dataset])\n",
    "twitter_pos['Target'] = '1'\n",
    "twitter_pos = twitter_pos[['tweet', 'Target']].reset_index(drop=True)\n",
    "twitter_pos = twitter_pos.sample(n=7327, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final twitter training set\n",
    "twitter_set = pd.concat([twitter_pos, twitter_neg])\n",
    "twitter_set['Target'] = twitter_set['Target'].astype('int')\n",
    "twitter_set = twitter_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 (optional):\n",
    "- test logreg crossval score of training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "#tfidf encode\n",
    "base_train_counts = count_vect.fit_transform(new_training_set['Description'])\n",
    "training_set_tfidf = tfidf_transformer.fit_transform(base_train_counts)\n",
    "x_tfidf = training_set_tfidf\n",
    "y_tfidf = new_training_set['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr(x_tfidf, y_tfidf, 10, 'precision', 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter training set scores 0.80-0.97 w/ precision and cv values 2, 5, 10. \n",
    "Archive training set scores around 0.65 w/ LogReg CV but around 0.80 w/ normal LogReg, neg precision is low w/ LogRegCV \n",
    "New training set scores 0.97-0.98 on LogRegCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:\n",
    "- Load prediction sets\n",
    "- Filter by language (eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_twitter = pd.read_pickle(path+'TWITTER_SEARCHES/PREDICTIONS/digital_archive_22.pkl')\n",
    "prediction_twitter = prediction_twitter.loc[prediction_twitter['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length \n",
    "len(prediction_twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:\n",
    "- run the predict function against chosen sets (twitter)\n",
    "- filter the results by prediction score (only positives) and optionally by inclusion of the 'music' kw\n",
    "- return a df w/ tweet, prediction value, score, probability, length of input and url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable for removing unwanted results \n",
    "discard = ['youtu', '404', 'Not Found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run w/ LogRegCV\n",
    "tweet_predict_cv = lr_model_predict_cv(twitter_set, 'tweet', 'Target', 5, 'precision', prediction_twitter, 'tweet', 'twitter_test_cv', '/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and display results \n",
    "tweet_predict_cv_df = tweet_predict_cv.copy()\n",
    "tweet_predict_cv_df = tweet_predict_cv_df.loc[tweet_predict_cv_df['Prediction'] == 1]\n",
    "tweet_predict_cv_df = tweet_predict_cv_df[~tweet_predict_cv_df.url.str.contains('|'.join(discard))]\n",
    "tweet_predict_cv_df = tweet_predict_cv_df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "tweet_predict_cv_df = tweet_predict_cv_df[['tweet', 'Prediction', 'Score', 'Probability', 'Input Length', 'url']]\n",
    "tweet_predict_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Input Length</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://t.co/RhyGUCu2Kv: hear songs by Finch i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.649459</td>\n",
       "      <td>[-1.0696996078424883, -0.4202410922158521]</td>\n",
       "      <td>154</td>\n",
       "      <td>https://tinyurl.com/Anne-Finch-Digital-Archive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  Prediction     Score  \\\n",
       "14  https://t.co/RhyGUCu2Kv: hear songs by Finch i...           1  0.649459   \n",
       "\n",
       "                                   Probability  Input Length  \\\n",
       "14  [-1.0696996078424883, -0.4202410922158521]           154   \n",
       "\n",
       "                                               url  \n",
       "14  https://tinyurl.com/Anne-Finch-Digital-Archive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optional filter by kw\n",
    "substring = 'music'\n",
    "mask = tweet_predict_cv_df.applymap(lambda x: substring in x.lower() if isinstance(x,str) else False).to_numpy()\n",
    "tweet_predict_cv_df_kw = tweet_predict_cv_df.loc[mask] \n",
    "tweet_predict_cv_df_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run w/ LogReg\n",
    "tweet_predict = lr_model_predict(twitter_set, 'tweet', 'Target', prediction_twitter, 'tweet', 'twitter_test', '/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and display results \n",
    "tweet_predict_df = tweet_predict.copy()\n",
    "tweet_predict_df = tweet_predict.loc[tweet_predict['Prediction'] == 1]\n",
    "tweet_predict_df = tweet_predict_df[~tweet_predict_df.url.str.contains('|'.join(discard))]\n",
    "tweet_predict_df = tweet_predict_df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "tweet_predict_df = tweet_predict_df[['tweet', 'Prediction', 'Score', 'Probability', 'Input Length', 'url']]\n",
    "tweet_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Input Length</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://t.co/RhyGUCu2Kv: hear songs by Finch i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947396</td>\n",
       "      <td>[-1.2750795021026953, -0.3276832286116716]</td>\n",
       "      <td>154</td>\n",
       "      <td>https://tinyurl.com/Anne-Finch-Digital-Archive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  Prediction     Score  \\\n",
       "11  https://t.co/RhyGUCu2Kv: hear songs by Finch i...           1  0.947396   \n",
       "\n",
       "                                   Probability  Input Length  \\\n",
       "11  [-1.2750795021026953, -0.3276832286116716]           154   \n",
       "\n",
       "                                               url  \n",
       "11  https://tinyurl.com/Anne-Finch-Digital-Archive  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optional filter by kw\n",
    "substring = 'music'\n",
    "mask = tweet_predict_df.applymap(lambda x: substring in x.lower() if isinstance(x,str) else False).to_numpy()\n",
    "tweet_predict_df_kw = tweet_predict_df.loc[mask] \n",
    "tweet_predict_df_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6:\n",
    "- grab links from twitter predictions and scrape them for text \n",
    "- return a new table that can be used as prediction against the musow training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URLs to list \n",
    "twitter_link_list_cv = [link for link in tweet_predict_cv_df['url'] if 'twitter' not in link]\n",
    "twitter_link_list = [link for link in tweet_predict_df['url'] if 'twitter' not in link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape URL list\n",
    "links_to_add_cv = scrape_links(twitter_link_list_cv)\n",
    "links_to_add = scrape_links(twitter_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty descriptions \n",
    "links_to_add_cv = links_to_add_cv[links_to_add_cv.Description != ''].reset_index(drop=True)\n",
    "links_to_add = links_to_add[links_to_add.Description != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7:\n",
    "- run the predict function against chosen sets (musoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with LogRegCV \n",
    "twitter_preds_cv = lr_model_predict_cv(new_training_set, 'Description', 'Target', 10, 'precision', links_to_add_cv, 'Description', 'extended_even_model_cv_twitter', '/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Input Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Description, URL, Prediction, Score, Probability, Input Length]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter results by positive value and score\n",
    "twitter_preds_cv_df = twitter_preds_cv.copy()\n",
    "twitter_preds_cv_df = twitter_preds_cv_df.loc[twitter_preds_cv_df['Prediction'] == 1]\n",
    "twitter_preds_cv_df = twitter_preds_cv_df[~twitter_preds_cv_df.Title.str.contains('|'.join(discard))]\n",
    "twitter_preds_cv_df.sort_values(by='Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with LogReg \n",
    "twitter_preds = lr_model_predict(new_training_set, 'Description', 'Target', links_to_add, 'Description', 'extended_even_model_twitter', '/Users/laurentfintoni/Desktop/University/COURSE DOCS/THESIS/Internship/musow-pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Input Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Not Here, Then Where?</td>\n",
       "      <td>3D Assets</td>\n",
       "      <td>https://oncyber.io/if-not-here-then-where</td>\n",
       "      <td>1</td>\n",
       "      <td>3.227110</td>\n",
       "      <td>[-3.2660150807696704, -0.03890527196295917]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Des Moines Register | Des Moines Public Library</td>\n",
       "      <td>Read full-text articles of today's Des Moines ...</td>\n",
       "      <td>https://buff.ly/3oqLORQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2.967700</td>\n",
       "      <td>[-3.0178426047078024, -0.050143025181493106]</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cuttly | Free Custom URL Shortener, Branded UR...</td>\n",
       "      <td>Keep calm and shorten/manage long URLs with cu...</td>\n",
       "      <td>https://cutt.ly/NO2xgZN, https://cutt.ly/AO2xYDx</td>\n",
       "      <td>1</td>\n",
       "      <td>2.611592</td>\n",
       "      <td>[-2.6824391251950415, -0.07084758020804563]</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Palestinian Museum -Digital Archive - الار...</td>\n",
       "      <td>صورة صورة التقطت عام 1970 لحسن الخطيب مع طلاب ...</td>\n",
       "      <td>https://palarchive.org/index.php/Detail/object...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.996386</td>\n",
       "      <td>[-2.123745466214168, -0.12735950083268982]</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Palestinian Museum -Digital Archive - الار...</td>\n",
       "      <td>صورة صورة التقطت عام 1970 لحسن الخطيب مع طلاب ...</td>\n",
       "      <td>https://cutt.ly/qO2IDot</td>\n",
       "      <td>1</td>\n",
       "      <td>1.996386</td>\n",
       "      <td>[-2.123745466214168, -0.12735950083268982]</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home | Search the archive | British Newspaper ...</td>\n",
       "      <td>Access hundreds of historic newspapers from al...</td>\n",
       "      <td>https://www.britishnewspaperarchive.co.uk/</td>\n",
       "      <td>1</td>\n",
       "      <td>1.862548</td>\n",
       "      <td>[-2.00688738048501, -0.14433974172840525]</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soutron LMS - Search</td>\n",
       "      <td>Learn more \\n\\nRead the latest\\n  Learn More\\n...</td>\n",
       "      <td>https://www.marshallfoundation.org/library/dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.787162</td>\n",
       "      <td>[-1.9419710429541304, -0.15480870871020935]</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soutron LMS - Search</td>\n",
       "      <td>Learn more \\n\\nRead the latest\\n  Learn More\\n...</td>\n",
       "      <td>https://www.marshallfoundation.org/library/dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.787162</td>\n",
       "      <td>[-1.9419710429541304, -0.15480870871020935]</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iDigOrion – Digital Archive | Orion Township P...</td>\n",
       "      <td>Welcome to iDigOrion, a research tool funded b...</td>\n",
       "      <td>https://orionlibrary.org/idigorion/</td>\n",
       "      <td>1</td>\n",
       "      <td>1.249140</td>\n",
       "      <td>[-1.501260406508946, -0.25212074232549736]</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Home Page - Anne Finch Digital Archive</td>\n",
       "      <td>Search options by Peter Cross, circa 1690 \\r\\n...</td>\n",
       "      <td>https://tinyurl.com/Anne-Finch-Digital-Archive</td>\n",
       "      <td>1</td>\n",
       "      <td>1.237588</td>\n",
       "      <td>[-1.4922949267309136, -0.25470650538082834]</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Browse by category - Newspapers - eResources -...</td>\n",
       "      <td>14 resources\\n \\nAlternative titles:\\n\\r\\n\\t\\t...</td>\n",
       "      <td>https://auth.nls.uk/eresources/browse/category/99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829735</td>\n",
       "      <td>[-1.1917113515779727, -0.3619762277492746]</td>\n",
       "      <td>8933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Collection Overview: Broadcast Programmes - Op...</td>\n",
       "      <td>The Open University works with broadcasters su...</td>\n",
       "      <td>https://www.open.ac.uk/library/digital-archive...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769597</td>\n",
       "      <td>[-1.1502223723281946, -0.38062572475495055]</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Just a moment...</td>\n",
       "      <td>Please enable Cookies and reload the page. Thi...</td>\n",
       "      <td>http://www.ccad.edu/blogs/ccad-launches-new-di...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594756</td>\n",
       "      <td>[-1.0341054559374, -0.43934917695471853]</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Friendswood Historical Archive</td>\n",
       "      <td>This catalog documents the twelfth school year...</td>\n",
       "      <td>https://friendswood.omeka.net</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541162</td>\n",
       "      <td>[-0.9998970894133641, -0.45873504182699393]</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Questioning theories - Open University Digital...</td>\n",
       "      <td>©2021. All rights reserved. The Open Universit...</td>\n",
       "      <td>https://www.open.ac.uk/library/digital-archive...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536735</td>\n",
       "      <td>[-0.9971008404094844, -0.46036626603622277]</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Anti-racist mathematics - Open University Digi...</td>\n",
       "      <td>©2021. All rights reserved. The Open Universit...</td>\n",
       "      <td>https://www.open.ac.uk/library/digital-archive...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536735</td>\n",
       "      <td>[-0.9971008404094844, -0.46036626603622277]</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T244 Managing in organisations - Open Universi...</td>\n",
       "      <td>©2021. All rights reserved. The Open Universit...</td>\n",
       "      <td>https://www.open.ac.uk/library/digital-archive...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536735</td>\n",
       "      <td>[-0.9971008404094844, -0.46036626603622277]</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Futurist Gerd Leonhard: Welcome to the Future ...</td>\n",
       "      <td>These are the best links and must-reads aggreg...</td>\n",
       "      <td>http://www.gerd.digital/archive/1004587</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287649</td>\n",
       "      <td>[-0.8472791613978947, -0.5596298124068672]</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                            If Not Here, Then Where?   \n",
       "1     Des Moines Register | Des Moines Public Library   \n",
       "2   Cuttly | Free Custom URL Shortener, Branded UR...   \n",
       "3   The Palestinian Museum -Digital Archive - الار...   \n",
       "4   The Palestinian Museum -Digital Archive - الار...   \n",
       "5   Home | Search the archive | British Newspaper ...   \n",
       "6                                Soutron LMS - Search   \n",
       "7                                Soutron LMS - Search   \n",
       "8   iDigOrion – Digital Archive | Orion Township P...   \n",
       "9              Home Page - Anne Finch Digital Archive   \n",
       "10  Browse by category - Newspapers - eResources -...   \n",
       "11  Collection Overview: Broadcast Programmes - Op...   \n",
       "12                                   Just a moment...   \n",
       "13                     Friendswood Historical Archive   \n",
       "14  Questioning theories - Open University Digital...   \n",
       "15  Anti-racist mathematics - Open University Digi...   \n",
       "16  T244 Managing in organisations - Open Universi...   \n",
       "17  Futurist Gerd Leonhard: Welcome to the Future ...   \n",
       "\n",
       "                                          Description  \\\n",
       "0                                           3D Assets   \n",
       "1   Read full-text articles of today's Des Moines ...   \n",
       "2   Keep calm and shorten/manage long URLs with cu...   \n",
       "3   صورة صورة التقطت عام 1970 لحسن الخطيب مع طلاب ...   \n",
       "4   صورة صورة التقطت عام 1970 لحسن الخطيب مع طلاب ...   \n",
       "5   Access hundreds of historic newspapers from al...   \n",
       "6   Learn more \\n\\nRead the latest\\n  Learn More\\n...   \n",
       "7   Learn more \\n\\nRead the latest\\n  Learn More\\n...   \n",
       "8   Welcome to iDigOrion, a research tool funded b...   \n",
       "9   Search options by Peter Cross, circa 1690 \\r\\n...   \n",
       "10  14 resources\\n \\nAlternative titles:\\n\\r\\n\\t\\t...   \n",
       "11  The Open University works with broadcasters su...   \n",
       "12  Please enable Cookies and reload the page. Thi...   \n",
       "13  This catalog documents the twelfth school year...   \n",
       "14  ©2021. All rights reserved. The Open Universit...   \n",
       "15  ©2021. All rights reserved. The Open Universit...   \n",
       "16  ©2021. All rights reserved. The Open Universit...   \n",
       "17  These are the best links and must-reads aggreg...   \n",
       "\n",
       "                                                  URL  Prediction     Score  \\\n",
       "0           https://oncyber.io/if-not-here-then-where           1  3.227110   \n",
       "1                             https://buff.ly/3oqLORQ           1  2.967700   \n",
       "2    https://cutt.ly/NO2xgZN, https://cutt.ly/AO2xYDx           1  2.611592   \n",
       "3   https://palarchive.org/index.php/Detail/object...           1  1.996386   \n",
       "4                             https://cutt.ly/qO2IDot           1  1.996386   \n",
       "5          https://www.britishnewspaperarchive.co.uk/           1  1.862548   \n",
       "6   https://www.marshallfoundation.org/library/dig...           1  1.787162   \n",
       "7   https://www.marshallfoundation.org/library/dig...           1  1.787162   \n",
       "8                 https://orionlibrary.org/idigorion/           1  1.249140   \n",
       "9      https://tinyurl.com/Anne-Finch-Digital-Archive           1  1.237588   \n",
       "10  https://auth.nls.uk/eresources/browse/category/99           1  0.829735   \n",
       "11  https://www.open.ac.uk/library/digital-archive...           1  0.769597   \n",
       "12  http://www.ccad.edu/blogs/ccad-launches-new-di...           1  0.594756   \n",
       "13                      https://friendswood.omeka.net           1  0.541162   \n",
       "14  https://www.open.ac.uk/library/digital-archive...           1  0.536735   \n",
       "15  https://www.open.ac.uk/library/digital-archive...           1  0.536735   \n",
       "16  https://www.open.ac.uk/library/digital-archive...           1  0.536735   \n",
       "17            http://www.gerd.digital/archive/1004587           1  0.287649   \n",
       "\n",
       "                                     Probability  Input Length  \n",
       "0    [-3.2660150807696704, -0.03890527196295917]             9  \n",
       "1   [-3.0178426047078024, -0.050143025181493106]           210  \n",
       "2    [-2.6824391251950415, -0.07084758020804563]           147  \n",
       "3     [-2.123745466214168, -0.12735950083268982]           331  \n",
       "4     [-2.123745466214168, -0.12735950083268982]           331  \n",
       "5      [-2.00688738048501, -0.14433974172840525]           913  \n",
       "6    [-1.9419710429541304, -0.15480870871020935]           150  \n",
       "7    [-1.9419710429541304, -0.15480870871020935]           150  \n",
       "8     [-1.501260406508946, -0.25212074232549736]           806  \n",
       "9    [-1.4922949267309136, -0.25470650538082834]          1186  \n",
       "10    [-1.1917113515779727, -0.3619762277492746]          8933  \n",
       "11   [-1.1502223723281946, -0.38062572475495055]           767  \n",
       "12      [-1.0341054559374, -0.43934917695471853]           174  \n",
       "13   [-0.9998970894133641, -0.45873504182699393]           614  \n",
       "14   [-0.9971008404094844, -0.46036626603622277]           320  \n",
       "15   [-0.9971008404094844, -0.46036626603622277]           320  \n",
       "16   [-0.9971008404094844, -0.46036626603622277]           320  \n",
       "17    [-0.8472791613978947, -0.5596298124068672]           411  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter results by positive value and score\n",
    "twitter_preds_df = twitter_preds.copy()\n",
    "twitter_preds_df = twitter_preds_df.loc[twitter_preds_df['Prediction'] == 1]\n",
    "twitter_preds_df = twitter_preds_df[~twitter_preds_df.Title.str.contains('|'.join(discard))]\n",
    "twitter_preds_df.sort_values(by='Score', ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
